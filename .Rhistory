pp_check(cancel_model, nreps = 100,
plotfun = "stat", stat = "proportion_cancel") +
xlab("probability of cancel")
tidy(cancel_model, effects = "fixed", conf.int = TRUE, conf.level = 0.80)
exp(posterior_interval(cancel_model,prob=.8))
classification_summary(model = cancel_model, data= hotel_bookings, cutoff = 0.5)
cancel_pred <- posterior_predict(cancel_model)
dim(cancel_pre)
cancel_pred <- posterior_predict(cancel_model)
dim(cancel_pred)
View(cancel_pred)
? colMeans
cancel_classifications <- hotel_bookings %>%
mutate(cancel_prob = colMeans(cancel_pred),
cancel_class = as.numeric(cancel_prob >= 0.5))
View(cancel_classifications)
cancel_classifications <- hotel_bookings %>%
mutate(cancel_prob = colMeans(cancel_pred),
cancel_class = as.numeric(cancel_prob >= 0.5),
match = cancel_class == is_canceled)
View(cancel_classifications)
mean(cancel_classifications$match)
cancel_classifications  %>%
group_by(cancel_class) %>% sum
cancel_classifications  %>%
group_by(cancel_class,is_canceled) %>% count
cancel_classifications  %>%
group_by(cancel_class,is_canceled) %>% count %>% pivot_longer()
cancel_classifications  %>%
group_by(cancel_class,is_canceled) %>% count %>% unstack
cancel_classifications  %>%
group_by(cancel_class,is_canceled) %>% count
cancel_classifications  %>%
group_by(cancel_class,is_canceled) %>% count %>% pivot_longer(-n,values_to=n)
cancel_classifications  %>%
group_by(cancel_class,is_canceled) %>% count %>% pivot_longer(n,values_to=n)
cancel_classifications  %>%
group_by(cancel_class,is_canceled) %>% count %>% pivot_longer(-is_canceled,values_to=n)
cancel_classifications  %>%
group_by(cancel_class,is_canceled) %>% count %>% pivot_longer(-is_canceled,names_to =  'count', values_to=n)
cancel_classifications  %>%
group_by(cancel_class,is_canceled) %>% count %>% pivot_longer(-is_canceled,names_to =  'count', values_to=n)
cancel_classifications  %>%
group_by(cancel_class,is_canceled) %>% count
cancel_classifications  %>%
group_by(cancel_class,is_canceled) %>% count %>% pivot_longer(!is_canceled,names_to =  'count', values_to=n)
cancel_classifications  %>%
group_by(cancel_class,is_canceled) %>% count %>% pivot_wider(names_from=is_cancelled,values_from=n)
cancel_classifications  %>%
group_by(cancel_class,is_canceled) %>% count %>% pivot_wider(names_from=is_canceled,values_from=n)
classification_summary(model = cancel_model, data= hotel_bookings, cutoff = 0.5)$confusion_matrix
mean(cancel_classifications$match)
cv_accuracy <- classification_summary_cv(
model = cancel_model, data = hotel_bookings, cutoff = 0.5, k = 10)
cv_accuracy$cv$overall_accuracy
cv_accuracy$cv
classification_summary(model = cancel_model, data= hotel_bookings, cutoff = 0.5)$accuracy_rates
classification_summary(model = cancel_model, data= hotel_bookings, cutoff = 0.2)$accuracy_rates
classification_summary(model = cancel_model, data= hotel_bookings, cutoff = 0.4)$accuracy_rates
classification_summary(model = cancel_model, data= hotel_bookings, cutoff = 0.3)$accuracy_rates
classification_summary(model = cancel_model, data= hotel_bookings, cutoff = 0.34)$accuracy_rates
classification_summary(model = cancel_model, data= hotel_bookings, cutoff = 0.32)$accuracy_rates
classification_summary(model = cancel_model, data= hotel_bookings, cutoff = 0.31)$accuracy_rates
classification_summary(model = cancel_model, data= hotel_bookings, cutoff = 0.3)$accuracy_rates
View(hotel_bookings)
cancel_guest <- posterior_predict(cancel_model, newdata = data.frame(previous_canellations = c(1), is_repeated_guest=c(0), average_daily_rate=c(100), lead_time= c(30)))
cancel_guest <- posterior_predict(cancel_model, newdata = data.frame(previous_cancellations = c(1),
is_repeated_guest=c(0), average_daily_rate=c(100),
lead_time= c(30)))
dim(cancel_pred)
cancel_guest <- posterior_predict(cancel_model, newdata = data.frame(previous_cancellations = c(1),
is_repeated_guest=c(0), average_daily_rate=c(100),
lead_time= c(30)))
dim(cancel_guest)
cancel_guest <- posterior_predict(cancel_model, newdata = data.frame(previous_cancellations = c(1),
is_repeated_guest=c(0), average_daily_rate=c(100),
lead_time= c(30)))
dim(cancel_guest)
mean(cancel_guest)
cv_accuracy <- classification_summary_cv(
model = cancel_model, data = hotel_bookings, cutoff = 0.3, k = 10)
cv_accuracy$cv
customer_model <- as.data.frame(cancel_model) %>%
mutate(log_odds = `(Intercept)` + previous_cancellations*1 + average_daily_rate*100 + lead_time*30,
odds = exp(log_odds),
prob = odds / (1 + odds),
Y = rbinom(20000, size = 1, prob = prob))
customer_mode$prop
customer_model$prop
customer_model$prob
mean(customer_model$prob)
dims(customer_model.Y)
dim(customer_model.Y)
dim(customer_model$Y)
customer_model$Y
mean(customer_model$Y)
# Load packages
library(bayesrules)
library(rstanarm)
library(bayesplot)
library(tidyverse)
library(tidybayes)
library(broom.mixed)
data("hotel_bookings")
hotel_bookings %>%
select(is_canceled)  %>% summarize(fraction_cancelled = mean(is_canceled==1))
hotel_bookings <- hotel_bookings %>%
select(is_canceled,lead_time, previous_cancellations, is_repeated_guest, average_daily_rate )
cancel_model <- stan_glm(is_canceled ~ lead_time + previous_cancellations + is_repeated_guest + average_daily_rate,
data = hotel_bookings, family = binomial,
prior_intercept = normal(0,1,autoscale=TRUE),
prior = normal(0,1, autoscale=TRUE),
chains = 4, iter = 5000*2, seed = 84735 )
tidy(cancel_model, effects = "fixed", conf.int = TRUE, conf.level = 0.80)
View(hotel_bookings)
customer_model2 <- as.data.frame(cancel_model) %>%
mutate(log_odds = `(Intercept)` + previous_cancellations*25 + is_repeated_guest + average_daily_rate*100 + lead_time*30,
odds = exp(log_odds),
prob = odds / (1 + odds),
Y = rbinom(20000, size = 1, prob = prob))
customer_model2 <- as.data.frame(cancel_model) %>%
mutate(log_odds = `(Intercept)` + previous_cancellations*25 + is_repeated_guest + average_daily_rate*100 + lead_time*30,
odds = exp(log_odds),
prob = odds / (1 + odds),
Y = rbinom(20000, size = 1, prob = prob))
mean(customer_mode2$Y)
customer_model2 <- as.data.frame(cancel_model) %>%
mutate(log_odds = `(Intercept)` + previous_cancellations*25 + is_repeated_guest + average_daily_rate*100 + lead_time*30,
odds = exp(log_odds),
prob = odds / (1 + odds),
Y = rbinom(20000, size = 1, prob = prob))
mean(customer_model2$Y)
classification_summary(model = cancel_model, data= hotel_bookings, cutoff = 0.2)$accuracy_rates
customer_model2 <- as.data.frame(cancel_model) %>%
mutate(log_odds = `(Intercept)` + previous_cancellations*25 + is_repeated_guest + average_daily_rate*100 + lead_time*30,
odds = exp(log_odds),
prob = odds / (1 + odds),
Y = rbinom(20000, size = 1, prob = prob))
mean(customer_model2$Y)
mean(customer_model2$prob)
min(customer_model2$prob)
customer_model2 <- as.data.frame(cancel_model) %>%
mutate(log_odds = `(Intercept)` + previous_cancellations*20 + is_repeated_guest + average_daily_rate*100 + lead_time*30,
odds = exp(log_odds),
prob = odds / (1 + odds),
Y = rbinom(20000, size = 1, prob = prob))
mean(customer_model2$Y)
mean(customer_model2$prob)
customer_model2 <- as.data.frame(cancel_model) %>%
mutate(log_odds = `(Intercept)` + previous_cancellations*10+ is_repeated_guest + average_daily_rate*100 + lead_time*30,
odds = exp(log_odds),
prob = odds / (1 + odds),
Y = rbinom(20000, size = 1, prob = prob))
mean(customer_model2$Y)
mean(customer_model2$prob)
# Load packages
library(bayesrules)
library(tidyverse)
library(rstanarm)
library(broom.mixed)
# Load data
data(cherry_blossom_sample)
running <- cherry_blossom_sample %>%
select(runner, age, net)
nrow(running)
list <- c('Wasson','Bietry', 'Cunningham', 'Hoff', 'Baldwin', 'Godfrey', 'Halle', 'Jackson')
list
sample(list,5)
library(ISLR2)
names(BrainCancer)
set.seed(4)
N <- 2000
Operators <- sample(5:15, N, replace = T)
Center <- sample(c("A", "B", "C"), N, replace = T)
Time <- sample(c("Morn.", "After.", "Even."), N, replace = T)
X <- model.matrix( ~ Operators + Center + Time)[, -1]
X[1:5, ]
true.beta <- c(0.04, -0.3, 0, 0.2, -0.2)
h.fn <- function(x) return(0.00001 * x)
library(coxed)
queuing <- sim.survdata(N = N, T = 1000, X = X,
beta = true.beta, hazard.fun = h.fn)
names(queuing)
head(queuing$data)
mean(queuing$data$failed)
View(queing$data)
View(queuing$data)
? sim.survdata
fit.Center <- survfit(Surv(y, failed) ~ Center,
data = queuing$data)
plot(fit.Center, xlab = "Seconds",
ylab = "Probability of Still Being on Hold",
col = c(2, 4, 5))
legend("topright",
c("Call Center A", "Call Center B", "Call Center C"),
col = c(2, 4, 5), lty = 1)
fit.Time <- survfit(Surv(y, failed) ~ Time,
data = queuing$data)
plot(fit.Time, xlab = "Seconds",
ylab = "Probability of Still Being on Hold",
col = c(2, 4, 5))
legend("topright", c("Morning", "Afternoon", "Evening"),
col = c(5, 2, 4), lty = 1)
survdiff(Surv(y, failed) ~ Center, data = queuing$data)
survdiff(Surv(y, failed) ~ Time, data = queuing$data)
fit.queuing <- coxph(Surv(y, failed) ~ .,
data = queuing$data)
fit.queuing
180*1.51
180*1.51/1.08
180*1.51*1.08
180*1.51
380*2.32/1.25
180*1.51/1.08
180*1.51/1.08*(1-0.0019)
180*(1+.51/.08)*(1-0.0019)
180*(1.51/.08)*(1-0.0019)
180*(1.51/.8)*(1-0.0019)
180*(1.51/1.8)*(1-0.0019)
180*(1.51/1.08)*(1-0.0019)
180*(1.51/1.08)*(1-0.0019)
180*(1.51/1.0)*(1-0.25)
260*2.32/1.25*(1-.0156)
360*2.32/1.25*(1-.0156)
360*2.32/1*(1-.0156)
360*(1+.32-.25)/1*(1-.0156)
360*(1+.32/.25)/1*(1-.0156)
360*(1+.32)/1*(1-.0156)
360*(1+1.32/.25)/1*(1-.0156)
360*(1+1.32)/.25*(1-.0156)
360*(1+1.32)/(1-.25)*(1-.0156)
360*(1+1.32)/(1+.25)*(1-.0156)
360*(1+1.32)*(1-.0156)
360*(1+1.32)*(1+.25)*(1-.0156)
exp(1.32)
exp(.24)
360*exp(1.32/.25)
360*exp(1.32-.25)
1+.1
exp(.1)
exp(.25)
exp(-.25)
wEff <- 360*2.32*(1-.0156)
wEff
832/wEff
wEff/832
360*2.32/.75*(1-0.0156)
360*2.32/(1+.25)*(1-0.0156)
360*2.32/(1+.025)*(1-0.0156)
360*2.32/(1+.0025)*(1-0.0156)
360*2.32/(1+.00025)*(1-0.0156)
360*2.32/(1-.00025)*(1-0.0156)
360*2.32/(1-.0025)*(1-0.0156)
360*2.32/(1-.025)*(1-0.0156)
360*2.32/(1-.25)*(1-0.0156)
360*2.32/(1-.25)*(1-0.0156)/2
? coffee_ratings
library(bayesrules)
? coffee_ratings
? trees
?radon
? roaches
knitr::opts_chunk$set(echo = TRUE)
fit.coxph <- coxph(Surv(Y, delta) ~ group, data = table)
knitr::opts_chunk$set(echo = TRUE)
library(ISLR2)
library(survival)
data(BrainCancer)
library(dplyr)
library(ggplot2)
BrainCancer %>%
count(status)
fit.surv <- survfit(Surv(time, status) ~ 1, data = BrainCancer)
plot(fit.surv, xlab = "Months",
ylab = "Estimated Probability of Survival", conf.int = .68)
# prepare to accumulate
num_boots = 200
surv_samp = tibble(times = fit.surv$time, sum = 0, sumsq=0)
for(i in seq(1,num_boots))
{
bootsample <- sample_n(BrainCancer, 88, replace = T)
fit.boot <- survfit(Surv(time, status) ~ 1, data = bootsample,conf.type='none')
boot_sum = summary(fit.boot, time = fit.surv$time, extend = TRUE)
surv_samp <- surv_samp %>%
mutate(sum = sum + boot_sum$cumhaz, sumsq = sumsq + boot_sum$cumhaz^2 )
}
# compute mean and standard deviation
surv_samp <- surv_samp %>%
mutate(cumhaz.mean = sum/num_boots, cumhaz.std = sqrt(sumsq/num_boots - cumhaz.mean^2)) %>%
mutate(surv.prob = exp(-cumhaz.mean), surv.prob_plusSE = exp(-(cumhaz.mean+cumhaz.std)),
surv.prob_minusSE = exp(-(cumhaz.mean-cumhaz.std)))
ggplot(data = surv_samp, aes(x=times) ) +
geom_line(aes(y=surv.prob)) +
geom_line(aes(y=surv.prob_plusSE), linetype="twodash") +
geom_line(aes(y=surv.prob_minusSE),linetype="twodash") +
scale_y_continuous (limits = c(0,1),  breaks=c(0,.2,.4,.6,.8,1))
fit.all <- coxph(
Surv(time, status) ~ ., data = BrainCancer)
fit.all
BrainCancer <- BrainCancer %>%
mutate(group_ki = factor(if_else(ki == 40, 60L,ki)))
fit.surv <- survfit(Surv(time, status) ~ group_ki, data = BrainCancer)
plot(fit.surv, xlab = "Months",
ylab = "Estimated Probability of Survival", conf.type = 'plain',
col = c(2,4,5,6,7))
legend("bottomleft", levels(BrainCancer$group_ki), col = c(2,4,5,6,7), lty = 1)
library(survival)
library(dplyr)
library(ggplot2)
table = tibble(Y=c(26.5 ,37.2, 57.3, 90.8, 20.2, 89.8 ), delta= c(1, 1, 1, 0, 0, 0),
group  = c(0,1,0,1,0,0))
fit.surv <- survfit(Surv(Y, delta) ~ group, data= table)
plot(fit.surv , xlab = "Y",
ylab = "Estimated Probability of Survival", col = c(2 ,4))
legend("bottomleft", c("group 1", "group 2"), col = c(2,4), lty = 1)
fit.coxph <- coxph(Surv(Y, delta) ~ group, data = table)
summary(fit.coxph)
survdiff(Surv(Y, delta) ~ group, data = table)
1/.7117
knitr::opts_chunk$set(echo = TRUE)
wheel <- c("DD", "7", "BBB", "BB", "B", "C", "0")
prob <- c(0.03, 0.03, 0.06, 0.1, 0.25, 0.01, 0.52)
get_symbols <- function() {
sample(wheel, size = 3, replace = TRUE,
prob = prob)
}
play <- function() {
symbols <- get_symbols()
#print(symbols)
structure(score(symbols), symbols = symbols, class = 'slots')
}
score <- function(symbols) {
# calculate a prize
diamonds <- sum(symbols == "DD")
# count cherries
cherries <- sum(symbols == 'C')
payouts <- c("DD" = 100, "7" = 80, "BBB" = 40, "BB" = 25,
"B" = 10, "C" = 10, "0" = 0)
slots <- symbols[symbols != "DD"] # ignore diamonds, since they are wild.
same <- length(unique(slots)) == 1
bars <- slots %in% c("B", "BB", "BBB")
if (diamonds == 3) # if all diamonds, slots will be empty
prize <- 100
else if (same) {
prize <- unname(payouts[slots[1]])
} else if (all(bars )) {
prize <-  5
} else if (cherries > 0) {
prize <- c(0,2,5)[cherries + diamonds + 1]
} else
{
prize <- 0
}
# Each diamond doubles the prize
prize * 2 ^ diamonds
}
print.slots <- function(prize,...){
# extract symbols
symbols <- attr(prize, "symbols")
# collapse symbols into single string
symbols <- paste(symbols, collapse = " ")
# combine symbol with prize as a character string
# \n is special escape sequence for a new line (i.e. return or enter)
string <- paste(symbols, prize, sep = "\n$")
# display character string in console without quotes
cat(string)
}
combos <- expand.grid(wheel, wheel, wheel, stringsAsFactors = FALSE)
colnames(combos) <- c("w1","w2","w3")
prob_df <- data.frame(prob,row.names = wheel)
prob_df
combos$w1p <- prob_df[combos$w1,]
combos$w2p <- prob_df[combos$w2,]
combos$w3p <- prob_df[combos$w3,]
combos$p <- combos$w1p * combos$w2p * combos$w3p
# I think there is a way to do this using vectorize
combos$prize = apply(combos[c('w1','w2','w3')],1,function(row) {score(c(row[1],row[2],row[3]))})
sum(combos$prize*combos$p)
winnings <- vector(length = 1000000)
for (i in 1:1000000) {
winnings[i] <- play()
}
mean(winnings)
knitr::opts_chunk$set(echo = TRUE)
x <- c( x=3, y=4, z=4)
x
x$x
x[x]
x
x[x]
x[z]
z
x.x
?setNames
setNames
attributes(setNames)
unname
x <- c(1,2,3)
dims(x)
dim(x)
nrow(x)
ncol(x)
structure(1:5, comment = "my attribute")
structure(1:5, comment = "my attribute")
s <- structure(1:5, comment = "my attribute")
s
attributes(s)
str(s)
now_ct <- as.POSIXct("2018-08-01 22:00", tz = "UTC")
now_ct
as.double(now_ct)
now()
now_ct
str(now_ct)
?st
attributes(now_ct)
sex_char <- c("m", "m", "m")
sex_factor <- factor(sex_char, levels = c("m", "f"))
t<- table(sex_factor)
t
attributes(t)
f1 <- factor(letters)
levels(f1) <- rev(levels(f1))
f1
attributes(f1)
letters
f1<- factor(letters)
str(f1)
f1
as.doubw(f1)
as.double(f1)
levels(f1) <- reverse(levels(f1))
levels(f1) <- reverse(levels(f1))
levels(f1) <- rev(levels(f1))
f1
as.double(f1)
f1
f2 <- rev(factor(letters))
f2
as.double(f2)
f3 <- factor(letters, levels = rev(letters))
f3
as.double(f3)
list(1,3,4)
ab <- list(1,3,4)
ab
unlist(ab)
as.vector(ab)
today <- Sys.date()
today <- Sys.date
today <- Sys.Date()
today
time <- Sys.time()
c(today,time)
typeof(c(today,time))
test1 <- c(today, time)
test1
str(test1)
class(test1)
type(test1)
typeof(test1)
attributes(test1)
attributes(time)
unlist(today,time)
test2 <- list(today, time)
test2
unlist(test2)
c(test2[[1]],test2[[2]])
unclass(c(test2[[1]],test2[[2]]))
library(tidyverse)
postcode_tbl = tibble(
n = c(1,2,3,4,5),
postcode = c("rh6 0aq", "EH11 4NW", "mk3 5qe", "PE15 8NB", "PA19 1YA") )
postcode
postcode_tbl
postcode_tble |> mutate(hashed = hash(postcode))
postcode_tbl |> mutate(hashed = hash(postcode))
library(rlang)
postcode_tbl |> mutate(hashed = hash(postcode))
postcode_tbl |> mutate(hashed = hash(rowwise(postcode))
)
library(tidyverse)
library(digest)
library(digest)
postcode_tbl <- postcode_tbl |>
mutate(hashed = purrr::map_chr(postcode, digest, algo='xxhash32'),
hash_num = as.numeric(paste("0x",hashed,sep="")))
postcode_tbl = tibble(
n = c(1,2,3,4,5),
postcode = c("rh6 0aq", "EH11 4NW", "mk3 5qe", "PE15 8NB", "PA19 1YA") )
library(digest)
postcode_tbl <- postcode_tbl |>
mutate(hashed = purrr::map_chr(postcode, digest, algo='xxhash32'),
hash_num = as.numeric(paste("0x",hashed,sep="")))
postcode_tbl
digest(c('sd','fred'))
digest(c('sd','bob'))
? predict
? predict.ranger
library(parsnip)
setwd("~/dataSciDev/ROS/ROSWork")
library(tidyverse)
library(rstanarm)
? read_delim
helicopters= read_delim('helicopters.txt',delim=" ")
problems(helicopters)
View(helicopters)
helicopters= read_delim('helicopters.txt')
helicopters= read_delim('helicopters.txt')
helicopters$time_sec
helicopters= read_delim('helicopters.txt', trim_ws = TRUE)
View(helicopters)
